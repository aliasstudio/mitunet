{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oz6oyBnIS-wc"
   },
   "outputs": [],
   "source": [
    "!pip install -q segmentation-models-pytorch roboflow pycocotools albumentations tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9TBjLXCJ4p4M"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"AssertionError: can only test a child process\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"^can only test a child process^\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"can only test a child process\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"_MultiProcessingDataLoaderIter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kSQZPzxpf4xy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from roboflow import Roboflow\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8racdnLiTdyQ"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "\n",
    "# Regional Dataset\n",
    "project = rf.workspace(\"workspace-ou3p7\").project(\"floorplancis_fpc\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"coco-segmentation\")\n",
    "\n",
    "# Cubicasa-5k Dataset\n",
    "# project = rf.workspace(\"workspace-ou3p7\").project(\"cubicasa-he2yn-bewqv\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"coco-segmentation\")\n",
    "\n",
    "dataset_location = dataset.location\n",
    "train_dir, train_annot = os.path.join(dataset_location, \"train\"), os.path.join(dataset_location, \"train\", \"_annotations.coco.json\")\n",
    "valid_dir, valid_annot = os.path.join(dataset_location, \"valid\"), os.path.join(dataset_location, \"valid\", \"_annotations.coco.json\")\n",
    "test_dir, test_annot = os.path.join(dataset_location, \"test\"), os.path.join(dataset_location, \"test\", \"_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XvciCbFupaob"
   },
   "outputs": [],
   "source": [
    "class COCOSegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transforms=None):\n",
    "        self.root_dir, self.transforms = root_dir, transforms\n",
    "        self.coco = COCO(annotation_file)\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "\n",
    "        self.wall_cat_id = self.coco.getCatIds(catNms=['wall'])\n",
    "        self.door_cat_id = self.coco.getCatIds(catNms=['door'])\n",
    "        self.window_cat_id = self.coco.getCatIds(catNms=['window'])\n",
    "        print(f\"ID found for classes: Wall={self.wall_cat_id}, Door={self.door_cat_id}, Window={self.window_cat_id}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    # Creates a mask for openings by calculating the geometry of a larger bounding box and drawing it directly.\n",
    "    def _create_thick_openings_mask(self, anns, h, w):\n",
    "            openings_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "            for ann in anns:\n",
    "                cat_id = ann['category_id']\n",
    "                if cat_id in self.door_cat_id or cat_id in self.window_cat_id:\n",
    "                    single_opening_mask = self.coco.annToMask(ann)\n",
    "\n",
    "                    _, binary_mask = cv2.threshold(single_opening_mask, 0, 255, cv2.THRESH_BINARY)\n",
    "                    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    if not contours: continue\n",
    "\n",
    "                    rect = cv2.minAreaRect(contours[0])\n",
    "\n",
    "                    center = rect[0]\n",
    "                    size = rect[1]\n",
    "                    angle = rect[2]\n",
    "\n",
    "                    thickness_to_add = 30\n",
    "                    if size[0] < size[1]:\n",
    "                        new_size = (size[0] + thickness_to_add, size[1])\n",
    "                    else:\n",
    "                        new_size = (size[0], size[1] + thickness_to_add)\n",
    "\n",
    "                    new_rect = (center, new_size, angle)\n",
    "                    new_box_points = np.intp(cv2.boxPoints(new_rect))\n",
    "\n",
    "                    cv2.drawContours(openings_mask, [new_box_points], 0, (255), -1)\n",
    "\n",
    "            return openings_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.root_dir, img_info['file_name'])\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        h, w = img_info['height'], img_info['width']\n",
    "        wall_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        for ann in anns:\n",
    "            if ann['category_id'] in self.wall_cat_id:\n",
    "                wall_mask = np.maximum(wall_mask, self.coco.annToMask(ann))\n",
    "\n",
    "        thick_openings_mask = self._create_thick_openings_mask(anns, h, w)\n",
    "        final_mask = cv2.subtract(wall_mask, thick_openings_mask)\n",
    "\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        image_h, image_w, _ = image.shape\n",
    "        mask_h, mask_w = final_mask.shape\n",
    "        if image_h != mask_h or image_w != mask_w:\n",
    "            final_mask = cv2.resize(final_mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=final_mask)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "        else:\n",
    "            mask = final_mask\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVLSITTdTheu"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = 512, 512\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Affine(\n",
    "        scale=(0.9, 1.1),\n",
    "        translate_percent=(-0.05, 0.05),\n",
    "        rotate=(-15, 15),\n",
    "        p=0.7,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "    ),\n",
    "    A.Perspective(p=0.3),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=1.0, alpha=120, sigma=120 * 0.05),\n",
    "        A.GridDistortion(p=1.0),\n",
    "    ], p=0.2),\n",
    "\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CLAHE(p=0.2),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(p=1.0),\n",
    "        A.ISONoise(p=1.0),\n",
    "    ], p=0.3),\n",
    "\n",
    "    A.Resize(IMG_WIDTH, IMG_HEIGHT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "valid_transforms = A.Compose([\n",
    "    A.Resize(IMG_WIDTH, IMG_HEIGHT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "from torch.utils.data import ConcatDataset, random_split, Subset\n",
    "\n",
    "raw_train_dataset = COCOSegmentationDataset(train_dir, train_annot, transforms=None)\n",
    "raw_valid_dataset = COCOSegmentationDataset(valid_dir, valid_annot, transforms=None)\n",
    "raw_test_dataset = COCOSegmentationDataset(test_dir, test_annot, transforms=None)\n",
    "\n",
    "full_dataset = ConcatDataset([raw_train_dataset, raw_valid_dataset, raw_test_dataset])\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "valid_size = len(full_dataset) - train_size\n",
    "\n",
    "train_subset, valid_subset = random_split(full_dataset, [train_size, valid_size],\n",
    "                                          generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "class TransformedSubset(Dataset):\n",
    "    def __init__(self, subset, transforms):\n",
    "        self.subset = subset\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask = self.subset[idx]\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=np.array(image), mask=mask)\n",
    "            return augmented['image'], augmented['mask']\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "train_dataset = TransformedSubset(train_subset, transforms=train_transforms)\n",
    "valid_dataset = TransformedSubset(valid_subset, transforms=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Images in train_loader: {len(train_loader.dataset)}\")\n",
    "print(f\"Images in valid_loader: {len(valid_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1H-Ay5Fshm8M"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_original_images(dataset, rows=3, cols=4):\n",
    "    num_images = rows * cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "    fig.suptitle(\"Original Dataset Images\", fontsize=20)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(min(num_images, len(dataset))):\n",
    "        image, _ = dataset[i]\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"Image {i}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    for j in range(num_images, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "visualize_original_images(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LWFkS4pT2tn"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_samples(dataset, num_samples=4):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
    "    fig.suptitle(\"Dataset images and masks\", fontsize=16)\n",
    "\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = dataset[idx]\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "        ax_img = axes[i, 0]\n",
    "        ax_img.imshow(image)\n",
    "        ax_img.set_title(f\"Image {idx}\")\n",
    "\n",
    "        ax_mask = axes[i, 1]\n",
    "        ax_mask.imshow(mask.numpy(), cmap='gray')\n",
    "        ax_mask.set_title(f\"Mask {idx}\")\n",
    "\n",
    "        for ax in [ax_img, ax_mask]:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('black')\n",
    "                spine.set_linewidth(1.5)\n",
    "                spine.set_visible(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_dataset, num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l7z1eAtolVjq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "def train_epoch(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, total_iou = 0.0, 0.0\n",
    "\n",
    "    epoch_tp = torch.tensor(0.0, device='cpu')\n",
    "    epoch_fp = torch.tensor(0.0, device='cpu')\n",
    "    epoch_fn = torch.tensor(0.0, device='cpu')\n",
    "    epoch_tn = torch.tensor(0.0, device='cpu')\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for images, masks in pbar:\n",
    "        images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        pred_probs = torch.sigmoid(outputs)\n",
    "        pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "        epoch_tp += tp.sum().detach().cpu()\n",
    "        epoch_fp += fp.sum().detach().cpu()\n",
    "        epoch_fn += fn.sum().detach().cpu()\n",
    "        epoch_tn += tn.sum().detach().cpu()\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    epoch_iou = smp.metrics.iou_score(epoch_tp, epoch_fp, epoch_fn, epoch_tn)\n",
    "\n",
    "    return running_loss / len(loader.dataset), epoch_iou.item()\n",
    "\n",
    "def valid_epoch(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    epoch_tp = torch.tensor(0.0, device='cpu')\n",
    "    epoch_fp = torch.tensor(0.0, device='cpu')\n",
    "    epoch_fn = torch.tensor(0.0, device='cpu')\n",
    "    epoch_tn = torch.tensor(0.0, device='cpu')\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    torch.cuda.synchronize(device)\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validation\")\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "            epoch_tp += tp.sum().detach().cpu()\n",
    "            epoch_fp += fp.sum().detach().cpu()\n",
    "            epoch_fn += fn.sum().detach().cpu()\n",
    "            epoch_tn += tn.sum().detach().cpu()\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    torch.cuda.synchronize(device)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    # VRAM\n",
    "    peak_vram_mb = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
    "\n",
    "    # FPS\n",
    "    total_time = end_time - start_time\n",
    "    total_images = len(loader.dataset)\n",
    "    fps = total_images / total_time\n",
    "\n",
    "    # Metrics\n",
    "    epoch_iou = smp.metrics.iou_score(epoch_tp, epoch_fp, epoch_fn, epoch_tn)\n",
    "    epoch_loss = running_loss / total_images\n",
    "\n",
    "    return epoch_loss, epoch_iou.item(), fps, peak_vram_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFZt0GgmOb36"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing SOTA architectures compared to the hybrid"
   ],
   "metadata": {
    "id": "PYNWNCLOt4V_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS = 30\n",
    "LR = 0.0001\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "\n",
    "LOSS_FUNCTIONS = {\n",
    "    \"Dice\": smp.losses.DiceLoss(mode='binary'),\n",
    "    \"Focal\": smp.losses.FocalLoss(mode='binary'),\n",
    "    \"Lovasz\": smp.losses.LovaszLoss(mode='binary'),\n",
    "    \"Tversky\": smp.losses.TverskyLoss(mode='binary', alpha=0.6, beta=0.4, gamma=1.0)\n",
    "}\n",
    "\n",
    "def get_model(model_name, encoder_name, hybrid=False):\n",
    "    params = {\n",
    "        \"encoder_name\": encoder_name,\n",
    "        \"encoder_weights\": \"imagenet\",\n",
    "        \"in_channels\": 3,\n",
    "        \"classes\": 1,\n",
    "    }\n",
    "\n",
    "    if model_name == \"Unet\":\n",
    "        if hybrid:\n",
    "            segformer_full = smp.Segformer(encoder_name=encoder_name, encoder_weights=\"imagenet\")\n",
    "            model = smp.Unet(\n",
    "                decoder_attention_type=\"scse\",\n",
    "                **{**params, \"encoder_weights\": None}\n",
    "            )\n",
    "            model.encoder = segformer_full.encoder\n",
    "        else:\n",
    "            model = smp.Unet(decoder_attention_type=\"scse\", **params)\n",
    "    elif model_name == \"UnetPlusPlus\":\n",
    "        model = smp.UnetPlusPlus(decoder_attention_type=\"scse\", **params)\n",
    "    elif model_name == \"DeepLabV3Plus\":\n",
    "        model = smp.DeepLabV3Plus(**params)\n",
    "    elif model_name == \"UperNet\":\n",
    "        model = smp.UPerNet(**params)\n",
    "    elif model_name == \"FPN\":\n",
    "        model = smp.FPN(**params)\n",
    "    elif model_name == \"Segformer\":\n",
    "        model = smp.Segformer(**params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model architecture: {model_name}\")\n",
    "\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def train_epoch(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    tp_tot, fp_tot, fn_tot, tn_tot = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            masks = masks.long()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(preds, masks, mode='binary')\n",
    "            tp_tot += tp.sum()\n",
    "            fp_tot += fp.sum()\n",
    "            fn_tot += fn.sum()\n",
    "            tn_tot += tn.sum()\n",
    "\n",
    "    iou = smp.metrics.iou_score(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    recall = smp.metrics.recall(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    precision = smp.metrics.precision(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    accuracy = smp.metrics.accuracy(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "\n",
    "    return iou, recall, precision, accuracy\n",
    "\n",
    "def benchmark_speed_memory(model, loader, device):\n",
    "    model.eval()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start_time = time.time()\n",
    "    total_frames = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            _ = model(images)\n",
    "            total_frames += images.size(0)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    fps = total_frames / (end_time - start_time)\n",
    "    vram_usage = torch.cuda.max_memory_allocated() / (1024 ** 2) # MiB\n",
    "\n",
    "    return fps, vram_usage\n",
    "\n",
    "experiments_config = [\n",
    "    {\n",
    "        \"model\": \"UperNet\",\n",
    "        \"encoder\": \"mit_b4\",\n",
    "        \"hybrid\": False,\n",
    "        \"tag\": \"UperNet (MiT-B4)\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Unet\",\n",
    "        \"encoder\": \"mit_b4\",\n",
    "        \"hybrid\": True,\n",
    "        \"tag\": \"MitUnet\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Unet\",\n",
    "        \"encoder\": \"resnet50\",\n",
    "        \"hybrid\": False,\n",
    "        \"tag\": \"Unet (scSE)\"\n",
    "    },\n",
    "        {\n",
    "        \"model\": \"UnetPlusPlus\",\n",
    "        \"encoder\": \"resnet50\",\n",
    "        \"hybrid\": False,\n",
    "        \"tag\": \"Unet++\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"DeepLabV3Plus\",\n",
    "        \"encoder\": \"resnet50\",\n",
    "        \"hybrid\": False,\n",
    "        \"tag\": \"DeepLabV3+\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Segformer\",\n",
    "        \"encoder\": \"mit_b4\",\n",
    "        \"hybrid\": False,\n",
    "        \"tag\": \"Segformer\"\n",
    "    },\n",
    "]\n",
    "\n",
    "results_data = []\n",
    "\n",
    "print(f\"\\nStart Comparative Benchmark: {len(experiments_config)} models x {len(LOSS_FUNCTIONS)} losses\")\n",
    "\n",
    "for config in experiments_config:\n",
    "    for loss_name, loss_fn in LOSS_FUNCTIONS.items():\n",
    "\n",
    "        experiment_name = f\"{config['tag']} + {loss_name}\"\n",
    "        print(f\"Training: {experiment_name}\")\n",
    "\n",
    "        model = get_model(config[\"model\"], config[\"encoder\"], config[\"hybrid\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "        best_iou = 0.0\n",
    "\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            train_loss = train_epoch(model, train_loader, loss_fn, optimizer, DEVICE)\n",
    "\n",
    "            iou, recall, precision, accuracy = evaluate_metrics(model, valid_loader, DEVICE)\n",
    "            scheduler.step(iou)\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "\n",
    "            print(f\"\\rEpoch {epoch}/{EPOCHS} | Loss: {train_loss:.4f} | IoU: {iou:.4f}\", end=\"\")\n",
    "        print(f\"\\nTraining finished. Best IoU during train: {best_iou:.4f}\")\n",
    "\n",
    "        print(\"Running final evaluation and benchmarks...\")\n",
    "        final_iou, final_recall, final_precision, final_accuracy = evaluate_metrics(model, valid_loader, DEVICE)\n",
    "        fps, vram = benchmark_speed_memory(model, valid_loader, DEVICE)\n",
    "\n",
    "        results_data.append({\n",
    "            \"Model Type\": config[\"tag\"],\n",
    "            \"Model Arch\": config[\"model\"],\n",
    "            \"Encoder\": config[\"encoder\"],\n",
    "            \"Loss Function\": loss_name,\n",
    "            \"IoU\": round(final_iou, 4),\n",
    "            \"Recall\": round(final_recall, 4),\n",
    "            \"Precision\": round(final_precision, 4),\n",
    "            \"Accuracy\": round(final_accuracy, 4),\n",
    "            \"FPS\": round(fps, 2),\n",
    "            \"VRAM (MiB)\": round(vram, 2)\n",
    "        })\n",
    "\n",
    "        del model, optimizer, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "df_results = df_results.sort_values(by=\"IoU\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\\nCOMPARATIVE TABLE\")\n",
    "print(df_results.to_string())\n",
    "\n",
    "df_results.to_excel(\"model_comparison_results.xlsx\", index=False)"
   ],
   "metadata": {
    "id": "PSuzqDWQNYCS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Tversky loss"
   ],
   "metadata": {
    "id": "8b1vMhMjkOWw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EPOCHS = 30\n",
    "LR = 0.0001\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "TVERSKY_ALPHAS = [0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def get_hybrid_model(encoder_name=\"mit_b4\"):\n",
    "    segformer_full = smp.Segformer(\n",
    "        encoder_name=encoder_name,\n",
    "        encoder_weights=\"imagenet\"\n",
    "    )\n",
    "    model = smp.Unet(\n",
    "        encoder_name=encoder_name,\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        decoder_attention_type=\"scse\"\n",
    "    )\n",
    "\n",
    "    model.encoder = segformer_full.encoder\n",
    "\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def train_epoch(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    tp_tot, fp_tot, fn_tot, tn_tot = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            masks = masks.long()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(preds, masks, mode='binary')\n",
    "            tp_tot += tp.sum()\n",
    "            fp_tot += fp.sum()\n",
    "            fn_tot += fn.sum()\n",
    "            tn_tot += tn.sum()\n",
    "\n",
    "    iou = smp.metrics.iou_score(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    recall = smp.metrics.recall(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    precision = smp.metrics.precision(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "    accuracy = smp.metrics.accuracy(tp_tot, fp_tot, fn_tot, tn_tot, reduction='micro').item()\n",
    "\n",
    "    return iou, recall, precision, accuracy\n",
    "\n",
    "results_data = []\n",
    "\n",
    "print(f\"\\nTversky Hyperparameter Tuning\")\n",
    "print(f\"Testing Alphas: {TVERSKY_ALPHAS}\")\n",
    "\n",
    "for alpha in TVERSKY_ALPHAS:\n",
    "    beta = 1.0 - alpha\n",
    "\n",
    "    loss_name = f\"Tversky (a={alpha}, b={beta:.2f})\"\n",
    "\n",
    "    print(f\"Experiment: {loss_name}\")\n",
    "\n",
    "    model = get_hybrid_model(encoder_name=\"mit_b4\")\n",
    "\n",
    "    loss_fn = smp.losses.TverskyLoss(\n",
    "        mode='binary',\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        gamma=1.0\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_iou = 0.0\n",
    "\n",
    "    pbar = tqdm(range(1, EPOCHS + 1), desc=f\"Training a={alpha}\")\n",
    "    for epoch in pbar:\n",
    "        train_loss = train_epoch(model, train_loader, loss_fn, optimizer, DEVICE)\n",
    "\n",
    "        iou, recall, precision, accuracy = evaluate_metrics(model, valid_loader, DEVICE)\n",
    "        scheduler.step(iou)\n",
    "\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "\n",
    "        pbar.set_postfix({\"Loss\": f\"{train_loss:.4f}\", \"IoU\": f\"{iou:.4f}\"})\n",
    "\n",
    "    print(f\"Finished. Best IoU: {best_iou:.4f}\")\n",
    "\n",
    "    final_iou, final_recall, final_precision, final_accuracy = evaluate_metrics(model, valid_loader, DEVICE)\n",
    "\n",
    "    results_data.append({\n",
    "        \"Model\": \"MitUnet\",\n",
    "        \"Loss Function\": \"Tversky\",\n",
    "        \"Alpha (FN penalty)\": alpha,\n",
    "        \"Beta (FP penalty)\": round(beta, 2),\n",
    "        \"IoU\": round(final_iou, 4),\n",
    "        \"Recall\": round(final_recall, 4),\n",
    "        \"Precision\": round(final_precision, 4),\n",
    "        \"Accuracy\": round(final_accuracy, 4)\n",
    "    })\n",
    "\n",
    "    del model, optimizer, scheduler, loss_fn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "df_results = df_results.sort_values(by=\"IoU\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\\nTVERSKY PARAMETER RESULTS\")\n",
    "print(df_results.to_string())\n",
    "\n",
    "try:\n",
    "    df_results.to_excel(\"tversky_tuning_results.xlsx\", index=False)\n",
    "    print(\"\\nResults saved to 'tversky_tuning_results.xlsx'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not save to Excel (install openpyxl). Saving to CSV. Error: {e}\")\n",
    "    df_results.to_csv(\"tversky_tuning_results.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(df_results[\"Alpha (FN penalty)\"], df_results[\"Recall\"], marker='o', label='Recall', color='green')\n",
    "plt.plot(df_results[\"Alpha (FN penalty)\"], df_results[\"Precision\"], marker='o', label='Precision', color='red')\n",
    "plt.plot(df_results[\"Alpha (FN penalty)\"], df_results[\"IoU\"], marker='x', label='IoU', color='blue', linestyle='--')\n",
    "\n",
    "plt.title(f\"Alpha impact on metrics\")\n",
    "plt.xlabel(\"Alpha (FN)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "sf10-G74zbPb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OogNuL5wELHS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MODEL_NAME = 'MitUNet_finetune'\n",
    "ENCODER_MITUNET = \"mit_b4\"\n",
    "EPOCHS_MITUNET = 30\n",
    "LR_MITUNET = 0.00001\n",
    "BEST_MITUNET_PATH = \"MitUNet_cubicasa-5k_a62_mit_b4_tversky_7606_20E.pth\"\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=\"imagenet\",\n",
    ")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    decoder_attention_type=\"scse\"\n",
    ")\n",
    "\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE)) # finetune\n",
    "model_mitunet.to(DEVICE)\n",
    "\n",
    "# loss_fn_mitunet = smp.losses.DiceLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.FocalLoss(mode='binary')\n",
    "loss_fn_mitunet = smp.losses.LovaszLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.TverskyLoss(\n",
    "#     mode='binary',\n",
    "#     alpha=0.7,\n",
    "#     beta=0.3,\n",
    "#     gamma=1.0\n",
    "# )\n",
    "\n",
    "optimizer_mitunet = torch.optim.Adam(model_mitunet.parameters(), lr=LR_MITUNET)\n",
    "lr_scheduler_mitunet = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_mitunet, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(f\"\\nStart training {MODEL_NAME}\")\n",
    "max_iou_mitunet = 0\n",
    "\n",
    "train_iou_history_su = []\n",
    "valid_iou_history_su = []\n",
    "train_loss_history_su = []\n",
    "valid_loss_history_su = []\n",
    "valid_fps_history_su = []\n",
    "valid_vram_history_su = []\n",
    "\n",
    "for epoch in range(1, EPOCHS_MITUNET + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS_MITUNET} ({MODEL_NAME})\")\n",
    "\n",
    "    train_loss, train_iou = train_epoch(model_mitunet, train_loader, loss_fn_mitunet, optimizer_mitunet, device=DEVICE)\n",
    "    valid_loss, valid_iou, fps, vram = valid_epoch(model_mitunet, valid_loader, loss_fn_mitunet, device=DEVICE)\n",
    "\n",
    "    train_loss_history_su.append(train_loss)\n",
    "    valid_loss_history_su.append(valid_loss)\n",
    "    train_iou_history_su.append(train_iou)\n",
    "    valid_iou_history_su.append(valid_iou)\n",
    "    valid_fps_history_su.append(fps)\n",
    "    valid_vram_history_su.append(vram)\n",
    "\n",
    "    lr_scheduler_mitunet.step(valid_iou)\n",
    "\n",
    "    print(f\"{MODEL_NAME} Train Loss: {train_loss:.4f} | {MODEL_NAME} Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"{MODEL_NAME} Train IoU: {train_iou:.4f} | {MODEL_NAME} Valid IoU: {valid_iou:.4f}\")\n",
    "    print(f\"Speed: {fps:.2f} FPS | VRAM: {vram:.2f} MiB\")\n",
    "\n",
    "    if valid_iou > max_iou_mitunet:\n",
    "        max_iou_mitunet = valid_iou\n",
    "        BEST_MITUNET_PATH = f'{MODEL_NAME.lower()}_{ENCODER_MITUNET}_{str(loss_fn_mitunet).lower().split('loss', 1)[0]}_{f\"{valid_iou:.4f}\"[2:]}_{epoch}E.pth'\n",
    "\n",
    "        if epoch > 3:\n",
    "          torch.save(model_mitunet.state_dict(), BEST_MITUNET_PATH)\n",
    "          print(f\"{MODEL_NAME} model saved! New best validation IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME} is over. Best IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "epochs_range = range(1, EPOCHS_MITUNET + 1)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_history_su, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, valid_loss_history_su, label='Validation Loss', marker='o')\n",
    "plt.title(f'Loss by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# IoU\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, train_iou_history_su, label='Train IoU', marker='o')\n",
    "plt.plot(epochs_range, valid_iou_history_su, label='Validation IoU', marker='o')\n",
    "plt.title(f'IoU by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('IoU Score', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# FPS\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, valid_fps_history_su, label='Validation FPS', marker='o', color='green')\n",
    "plt.title(f'FPS ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('FPS', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# VRAM\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_range, valid_vram_history_su, label='Peak VRAM Usage', marker='o', color='purple')\n",
    "plt.title(f'Peak VRAM Usage (MiB) ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('VRAM (MiB)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYmovyLzfGdq"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Metrics\")\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "            total_tp += tp.sum()\n",
    "            total_fp += fp.sum()\n",
    "            total_fn += fn.sum()\n",
    "            total_tn += tn.sum()\n",
    "\n",
    "    final_iou = smp.metrics.iou_score(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_recall = smp.metrics.recall(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_precision = smp.metrics.precision(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_accuracy = smp.metrics.accuracy(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "\n",
    "    return {\n",
    "        \"IoU\": final_iou.item(),\n",
    "        \"Recall\": final_recall.item(),\n",
    "        \"Precision\": final_precision.item(),\n",
    "        \"Accuracy\": final_accuracy.item()\n",
    "    }\n",
    "\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE))\n",
    "\n",
    "print(f\"Evaluating {BEST_MITUNET_PATH}\")\n",
    "metrics = evaluate_model(model_mitunet, valid_loader, device=DEVICE)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  - IoU:       {metrics['IoU']:.4f}\")\n",
    "print(f\"  - Recall:    {metrics['Recall']:.4f}\")\n",
    "print(f\"  - Precision: {metrics['Precision']:.4f}\")\n",
    "print(f\"  - Accuracy:  {metrics['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "MODEL_NAME = 'MitUNet_finetune'\n",
    "ENCODER_MITUNET = \"mit_b4\"\n",
    "EPOCHS_MITUNET = 30\n",
    "LR_MITUNET = 0.00001\n",
    "BEST_MITUNET_PATH = \"MitUNet_cubicasa-5k_a62_mit_b4_tversky_7606_20E.pth\"\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=\"imagenet\",\n",
    ")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    decoder_attention_type=\"scse\"\n",
    ")\n",
    "\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE)) # finetune\n",
    "model_mitunet.to(DEVICE)\n",
    "\n",
    "# loss_fn_mitunet = smp.losses.DiceLoss(mode='binary')\n",
    "loss_fn_mitunet = smp.losses.FocalLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.LovaszLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.TverskyLoss(\n",
    "#     mode='binary',\n",
    "#     alpha=0.7,\n",
    "#     beta=0.3,\n",
    "#     gamma=1.0\n",
    "# )\n",
    "\n",
    "optimizer_mitunet = torch.optim.Adam(model_mitunet.parameters(), lr=LR_MITUNET)\n",
    "lr_scheduler_mitunet = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_mitunet, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(f\"\\n Training {MODEL_NAME} \")\n",
    "max_iou_mitunet = 0\n",
    "\n",
    "train_iou_history_su = []\n",
    "valid_iou_history_su = []\n",
    "train_loss_history_su = []\n",
    "valid_loss_history_su = []\n",
    "valid_fps_history_su = []\n",
    "valid_vram_history_su = []\n",
    "\n",
    "for epoch in range(1, EPOCHS_MITUNET + 1):\n",
    "    print(f\"\\n Epoch {epoch}/{EPOCHS_MITUNET} ({MODEL_NAME}) \")\n",
    "\n",
    "    train_loss, train_iou = train_epoch(model_mitunet, train_loader, loss_fn_mitunet, optimizer_mitunet, device=DEVICE)\n",
    "    valid_loss, valid_iou, fps, vram = valid_epoch(model_mitunet, valid_loader, loss_fn_mitunet, device=DEVICE)\n",
    "\n",
    "    train_loss_history_su.append(train_loss)\n",
    "    valid_loss_history_su.append(valid_loss)\n",
    "    train_iou_history_su.append(train_iou)\n",
    "    valid_iou_history_su.append(valid_iou)\n",
    "    valid_fps_history_su.append(fps)\n",
    "    valid_vram_history_su.append(vram)\n",
    "\n",
    "    lr_scheduler_mitunet.step(valid_iou)\n",
    "\n",
    "    print(f\"{MODEL_NAME} Train Loss: {train_loss:.4f} | {MODEL_NAME} Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"{MODEL_NAME} Train IoU: {train_iou:.4f} | {MODEL_NAME} Valid IoU: {valid_iou:.4f}\")\n",
    "    print(f\"Speed: {fps:.2f} FPS | VRAM: {vram:.2f} MiB\")\n",
    "\n",
    "    if valid_iou > max_iou_mitunet:\n",
    "        max_iou_mitunet = valid_iou\n",
    "        BEST_MITUNET_PATH = f'{MODEL_NAME.lower()}_{ENCODER_MITUNET}_{str(loss_fn_mitunet).lower().split('loss', 1)[0]}_{f\"{valid_iou:.4f}\"[2:]}_{epoch}E.pth'\n",
    "\n",
    "        if epoch > 3:\n",
    "          torch.save(model_mitunet.state_dict(), BEST_MITUNET_PATH)\n",
    "          print(f\"ðŸ† {MODEL_NAME} model saved! New best validation IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME} is over. Best IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "epochs_range = range(1, EPOCHS_MITUNET + 1)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_history_su, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, valid_loss_history_su, label='Validation Loss', marker='o')\n",
    "plt.title(f'Loss by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# IoU\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, train_iou_history_su, label='Train IoU', marker='o')\n",
    "plt.plot(epochs_range, valid_iou_history_su, label='Validation IoU', marker='o')\n",
    "plt.title(f'IoU by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('IoU Score', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# FPS\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, valid_fps_history_su, label='Validation FPS', marker='o', color='green')\n",
    "plt.title(f'FPS ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('FPS', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# VRAM\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_range, valid_vram_history_su, label='Peak VRAM Usage', marker='o', color='purple')\n",
    "plt.title(f'Peak VRAM Usage (MiB) ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('VRAM (MiB)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "EuPjN7NSUlHh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Metrics\")\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "            total_tp += tp.sum()\n",
    "            total_fp += fp.sum()\n",
    "            total_fn += fn.sum()\n",
    "            total_tn += tn.sum()\n",
    "\n",
    "    final_iou = smp.metrics.iou_score(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_recall = smp.metrics.recall(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_precision = smp.metrics.precision(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_accuracy = smp.metrics.accuracy(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "\n",
    "    return {\n",
    "        \"IoU\": final_iou.item(),\n",
    "        \"Recall\": final_recall.item(),\n",
    "        \"Precision\": final_precision.item(),\n",
    "        \"Accuracy\": final_accuracy.item()\n",
    "    }\n",
    "\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE))\n",
    "\n",
    "print(f\"Evaluating {BEST_MITUNET_PATH}\")\n",
    "metrics = evaluate_model(model_mitunet, valid_loader, device=DEVICE)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  - IoU:       {metrics['IoU']:.4f}\")\n",
    "print(f\"  - Recall:    {metrics['Recall']:.4f}\")\n",
    "print(f\"  - Precision: {metrics['Precision']:.4f}\")\n",
    "print(f\"  - Accuracy:  {metrics['Accuracy']:.4f}\")"
   ],
   "metadata": {
    "id": "ZsfP4ewYUs7Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "MODEL_NAME = 'MitUNet_finetune'\n",
    "ENCODER_MITUNET = \"mit_b4\"\n",
    "EPOCHS_MITUNET = 30\n",
    "LR_MITUNET = 0.00001\n",
    "BEST_MITUNET_PATH = \"MitUNet_cubicasa-5k_a62_mit_b4_tversky_7606_20E.pth\"\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=\"imagenet\",\n",
    ")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    decoder_attention_type=\"scse\"\n",
    ")\n",
    "\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE)) # finetune\n",
    "model_mitunet.to(DEVICE)\n",
    "\n",
    "loss_fn_mitunet = smp.losses.DiceLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.FocalLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.LovaszLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.TverskyLoss(\n",
    "#     mode='binary',\n",
    "#     alpha=0.7,\n",
    "#     beta=0.3,\n",
    "#     gamma=1.0\n",
    "# )\n",
    "\n",
    "optimizer_mitunet = torch.optim.Adam(model_mitunet.parameters(), lr=LR_MITUNET)\n",
    "lr_scheduler_mitunet = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_mitunet, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME}\")\n",
    "max_iou_mitunet = 0\n",
    "\n",
    "train_iou_history_su = []\n",
    "valid_iou_history_su = []\n",
    "train_loss_history_su = []\n",
    "valid_loss_history_su = []\n",
    "valid_fps_history_su = []\n",
    "valid_vram_history_su = []\n",
    "\n",
    "for epoch in range(1, EPOCHS_MITUNET + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS_MITUNET} ({MODEL_NAME})\")\n",
    "\n",
    "    train_loss, train_iou = train_epoch(model_mitunet, train_loader, loss_fn_mitunet, optimizer_mitunet, device=DEVICE)\n",
    "    valid_loss, valid_iou, fps, vram = valid_epoch(model_mitunet, valid_loader, loss_fn_mitunet, device=DEVICE)\n",
    "\n",
    "    train_loss_history_su.append(train_loss)\n",
    "    valid_loss_history_su.append(valid_loss)\n",
    "    train_iou_history_su.append(train_iou)\n",
    "    valid_iou_history_su.append(valid_iou)\n",
    "    valid_fps_history_su.append(fps)\n",
    "    valid_vram_history_su.append(vram)\n",
    "\n",
    "    lr_scheduler_mitunet.step(valid_iou)\n",
    "\n",
    "    print(f\"{MODEL_NAME} Train Loss: {train_loss:.4f} | {MODEL_NAME} Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"{MODEL_NAME} Train IoU: {train_iou:.4f} | {MODEL_NAME} Valid IoU: {valid_iou:.4f}\")\n",
    "    print(f\"Speed: {fps:.2f} FPS | VRAM: {vram:.2f} MiB\")\n",
    "\n",
    "    if valid_iou > max_iou_mitunet:\n",
    "        max_iou_mitunet = valid_iou\n",
    "        BEST_MITUNET_PATH = f'{MODEL_NAME.lower()}_{ENCODER_MITUNET}_{str(loss_fn_mitunet).lower().split('loss', 1)[0]}_{f\"{valid_iou:.4f}\"[2:]}_{epoch}E.pth'\n",
    "\n",
    "        if epoch > 3:\n",
    "          torch.save(model_mitunet.state_dict(), BEST_MITUNET_PATH)\n",
    "          print(f\"{MODEL_NAME} model saved! New best validation IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME} is over. Best IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "epochs_range = range(1, EPOCHS_MITUNET + 1)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_history_su, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, valid_loss_history_su, label='Validation Loss', marker='o')\n",
    "plt.title(f'Loss by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# IoU\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, train_iou_history_su, label='Train IoU', marker='o')\n",
    "plt.plot(epochs_range, valid_iou_history_su, label='Validation IoU', marker='o')\n",
    "plt.title(f'IoU by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('IoU Score', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# FPS\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, valid_fps_history_su, label='Validation FPS', marker='o', color='green')\n",
    "plt.title(f'FPS ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('FPS', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# VRAM\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_range, valid_vram_history_su, label='Peak VRAM Usage', marker='o', color='purple')\n",
    "plt.title(f'Peak VRAM Usage (MiB) ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('VRAM (MiB)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Metrics\")\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "            total_tp += tp.sum()\n",
    "            total_fp += fp.sum()\n",
    "            total_fn += fn.sum()\n",
    "            total_tn += tn.sum()\n",
    "\n",
    "    final_iou = smp.metrics.iou_score(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_recall = smp.metrics.recall(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_precision = smp.metrics.precision(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_accuracy = smp.metrics.accuracy(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "\n",
    "    return {\n",
    "        \"IoU\": final_iou.item(),\n",
    "        \"Recall\": final_recall.item(),\n",
    "        \"Precision\": final_precision.item(),\n",
    "        \"Accuracy\": final_accuracy.item()\n",
    "    }\n",
    "\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE))\n",
    "\n",
    "print(f\"Evaluating {BEST_MITUNET_PATH}\")\n",
    "metrics = evaluate_model(model_mitunet, valid_loader, device=DEVICE)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  - IoU:       {metrics['IoU']:.4f}\")\n",
    "print(f\"  - Recall:    {metrics['Recall']:.4f}\")\n",
    "print(f\"  - Precision: {metrics['Precision']:.4f}\")\n",
    "print(f\"  - Accuracy:  {metrics['Accuracy']:.4f}\")"
   ],
   "metadata": {
    "id": "uv2_qnbKUvD3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "MODEL_NAME = 'MitUNet_finetune'\n",
    "ENCODER_MITUNET = \"mit_b4\"\n",
    "EPOCHS_MITUNET = 30\n",
    "LR_MITUNET = 0.00001\n",
    "BEST_MITUNET_PATH = \"MitUNet_cubicasa-5k_a62_mit_b4_tversky_7606_20E.pth\"\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=\"imagenet\",\n",
    ")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=ENCODER_MITUNET,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    decoder_attention_type=\"scse\"\n",
    ")\n",
    "\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE)) # finetune\n",
    "model_mitunet.to(DEVICE)\n",
    "\n",
    "# loss_fn_mitunet = smp.losses.DiceLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.FocalLoss(mode='binary')\n",
    "loss_fn_mitunet = smp.losses.LovaszLoss(mode='binary')\n",
    "# loss_fn_mitunet = smp.losses.TverskyLoss(\n",
    "#     mode='binary',\n",
    "#     alpha=0.6,\n",
    "#     beta=0.4,\n",
    "#     gamma=1.0\n",
    "# )\n",
    "\n",
    "optimizer_mitunet = torch.optim.Adam(model_mitunet.parameters(), lr=LR_MITUNET)\n",
    "lr_scheduler_mitunet = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_mitunet, mode='max', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME}\")\n",
    "max_iou_mitunet = 0\n",
    "\n",
    "train_iou_history_su = []\n",
    "valid_iou_history_su = []\n",
    "train_loss_history_su = []\n",
    "valid_loss_history_su = []\n",
    "valid_fps_history_su = []\n",
    "valid_vram_history_su = []\n",
    "\n",
    "for epoch in range(1, EPOCHS_MITUNET + 1):\n",
    "    print(f\"\\n Epoch {epoch}/{EPOCHS_MITUNET} ({MODEL_NAME}) \")\n",
    "\n",
    "    train_loss, train_iou = train_epoch(model_mitunet, train_loader, loss_fn_mitunet, optimizer_mitunet, device=DEVICE)\n",
    "    valid_loss, valid_iou, fps, vram = valid_epoch(model_mitunet, valid_loader, loss_fn_mitunet, device=DEVICE)\n",
    "\n",
    "    train_loss_history_su.append(train_loss)\n",
    "    valid_loss_history_su.append(valid_loss)\n",
    "    train_iou_history_su.append(train_iou)\n",
    "    valid_iou_history_su.append(valid_iou)\n",
    "    valid_fps_history_su.append(fps)\n",
    "    valid_vram_history_su.append(vram)\n",
    "\n",
    "    lr_scheduler_mitunet.step(valid_iou)\n",
    "\n",
    "    print(f\"{MODEL_NAME} Train Loss: {train_loss:.4f} | {MODEL_NAME} Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"{MODEL_NAME} Train IoU: {train_iou:.4f} | {MODEL_NAME} Valid IoU: {valid_iou:.4f}\")\n",
    "    print(f\"Speed: {fps:.2f} FPS | VRAM: {vram:.2f} MiB\")\n",
    "\n",
    "    if valid_iou > max_iou_mitunet:\n",
    "        max_iou_mitunet = valid_iou\n",
    "        BEST_MITUNET_PATH = f'{MODEL_NAME.lower()}_{ENCODER_MITUNET}_{str(loss_fn_mitunet).lower().split('loss', 1)[0]}_{f\"{valid_iou:.4f}\"[2:]}_{epoch}E.pth'\n",
    "\n",
    "        if epoch > 3:\n",
    "          torch.save(model_mitunet.state_dict(), BEST_MITUNET_PATH)\n",
    "          print(f\"ðŸ† {MODEL_NAME} model saved! New best validation IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining {MODEL_NAME} is over. Best IoU: {max_iou_mitunet:.4f}\")\n",
    "\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_history_su, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, valid_loss_history_su, label='Validation Loss', marker='o')\n",
    "plt.title(f'Loss by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# IoU\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, train_iou_history_su, label='Train IoU', marker='o')\n",
    "plt.plot(epochs_range, valid_iou_history_su, label='Validation IoU', marker='o')\n",
    "plt.title(f'IoU by epoch ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('IoU Score', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# FPS\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, valid_fps_history_su, label='Validation FPS', marker='o', color='green')\n",
    "plt.title(f'FPS ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('FPS', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# VRAM\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_range, valid_vram_history_su, label='Peak VRAM Usage', marker='o', color='purple')\n",
    "plt.title(f'Peak VRAM Usage (MiB) ({MODEL_NAME})', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('VRAM (MiB)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Metrics\")\n",
    "        for images, masks in pbar:\n",
    "            images, masks = images.to(device), masks.to(device).unsqueeze(1).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            pred_probs = torch.sigmoid(outputs)\n",
    "            pred_masks = (pred_probs > 0.5).float()\n",
    "\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(pred_masks.long(), masks.long(), mode='binary')\n",
    "\n",
    "            total_tp += tp.sum()\n",
    "            total_fp += fp.sum()\n",
    "            total_fn += fn.sum()\n",
    "            total_tn += tn.sum()\n",
    "\n",
    "    final_iou = smp.metrics.iou_score(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_recall = smp.metrics.recall(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_precision = smp.metrics.precision(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "    final_accuracy = smp.metrics.accuracy(total_tp, total_fp, total_fn, total_tn, reduction='micro')\n",
    "\n",
    "    return {\n",
    "        \"IoU\": final_iou.item(),\n",
    "        \"Recall\": final_recall.item(),\n",
    "        \"Precision\": final_precision.item(),\n",
    "        \"Accuracy\": final_accuracy.item()\n",
    "    }\n",
    "\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE))\n",
    "\n",
    "print(f\"Evaluating {BEST_MITUNET_PATH}\")\n",
    "metrics = evaluate_model(model_mitunet, valid_loader, device=DEVICE)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  - IoU:       {metrics['IoU']:.4f}\")\n",
    "print(f\"  - Recall:    {metrics['Recall']:.4f}\")\n",
    "print(f\"  - Precision: {metrics['Precision']:.4f}\")\n",
    "print(f\"  - Accuracy:  {metrics['Accuracy']:.4f}\")"
   ],
   "metadata": {
    "id": "Sc5WAoYmU3UU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0_19k0UT_eC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inference_transforms = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "def predict(model, image_rgb):\n",
    "    model.eval()\n",
    "    augmented = inference_transforms(image=image_rgb)\n",
    "    image_tensor = augmented['image'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        mask = (probs > 0.5).float()\n",
    "\n",
    "    result_mask = mask.cpu().squeeze().numpy()\n",
    "    return result_mask\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(\n",
    "    encoder_name=\"mit_b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    ")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=\"mit_b4\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    decoder_attention_type=\"scse\",\n",
    ")\n",
    "\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.to(DEVICE)\n",
    "model_mitunet.eval()\n",
    "\n",
    "valid_dataset_raw = COCOSegmentationDataset(valid_dir, valid_annot, transforms=None)\n",
    "\n",
    "random_idx = random.randint(0, len(valid_dataset_raw) - 1)\n",
    "original_image, ground_truth_mask = valid_dataset_raw[random_idx]\n",
    "\n",
    "segunet_prediction = predict(model_mitunet, original_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title(f\"Original\\n(Index: {random_idx})\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(ground_truth_mask, cmap='gray')\n",
    "axes[1].set_title(\"Ground Truth\")\n",
    "\n",
    "axes[2].imshow(segunet_prediction, cmap='gray')\n",
    "axes[2].set_title(\"MitUnet Prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9J6aKNdU40B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "\n",
    "BEST_MITUNET_PATH = \"mitunet_finetune_a6_mit_b4_tversky_8864_28E.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "inference_transforms = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "segformer_for_encoder = smp.Segformer(encoder_name=\"mit_b4\", encoder_weights=\"imagenet\")\n",
    "transformer_encoder = segformer_for_encoder.encoder\n",
    "model_mitunet = smp.Unet(\n",
    "    encoder_name=\"mit_b4\", encoder_weights=None, in_channels=3, classes=1, decoder_attention_type=\"scse\"\n",
    ")\n",
    "model_mitunet.encoder = transformer_encoder\n",
    "model_mitunet.load_state_dict(torch.load(BEST_MITUNET_PATH, map_location=DEVICE))\n",
    "model_mitunet.to(DEVICE)\n",
    "model_mitunet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbBejVE5-Hh3"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzksgvIpeO09"
   },
   "outputs": [],
   "source": [
    "def predict(model, image_rgb):\n",
    "    model.eval()\n",
    "    augmented = inference_transforms(image=image_rgb)\n",
    "    image_tensor = augmented['image'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        mask = (probs > 0.5).float()\n",
    "\n",
    "    result_mask = mask.cpu().squeeze().numpy()\n",
    "    return result_mask\n",
    "\n",
    "\n",
    "for file_name in uploaded.keys():\n",
    "    print(f\"\\nProcessing: {file_name}\")\n",
    "\n",
    "    image_bytes = uploaded[file_name]\n",
    "    nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "    image_bgr = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    original_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    segunet_prediction = predict(model_mitunet, original_image)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 6))\n",
    "\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(segunet_prediction, cmap='gray')\n",
    "    axes[1].set_title(\"MitUNet\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_SZ2VmWJYY4H"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
